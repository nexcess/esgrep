#!/usr/bin/env python3.6
import time
import argparse
import sys
import os
import errno
import yaml
import json
import asyncio
import elasticsearch
import elasticsearch.helpers
from signal import signal, SIGINT, SIGPIPE, SIG_DFL

def format_docs(doc, args):
    if args.full_docs:
        final_doc = doc
    else:
        final_doc = doc['_source']
    if args.format == 'json':
        msg = json.dumps(final_doc)
    elif args.format == 'txt':
        msg = '{0} {1} {2}'.format(
                doc['_source']['@timestamp'],
                doc['_source']['host']['name'],
                doc['_source']['message']
               )
    return msg

def print_docs(es, query, args):
    """ construct and return a scroller for a given query """
    scroller = elasticsearch.helpers.scan(
                    es,
                    query,
                    index=args.index,
                    request_timeout=float(args.timeout),
                    preserve_order=args.no_preserve_order
                )
    for doc in scroller:
        print(format_docs(doc, args))

async def async_print_docs(es, query, args):
    scroller = elasticsearch.helpers.async_scan(
        client=es,
        query=query,
        index=args.index,
        request_timeout=float(args.timeout)
    )
    async for doc in scroller:
        print(format_docs(doc, args))
    await es.close()

def load_config(config_path):
    with open(config_path, 'r') as file:
        config = yaml.load(file, Loader=yaml.BaseLoader)
    return config

def build_query_string_query(args):
    """ build a kibana style query_string query """
    query = {
        'query': {
            'bool': {
                'filter': [
                    {
                        'query_string': {
                            'query': args.query,
                            'analyze_wildcard': 'true'
                        }
                    }
                ]
            }
        }
    }
    # build and add time range 
    # only add to query if --timestart or --timeend flags passed
    if args.timestart or args.timeend:
        time_range = { 'range': { args.timefield: {} } }
        if args.timestart:
            time_range['range'][args.timefield]['gte'] = args.timestart
        if args.timeend:
            time_range['range'][args.timefield]['lt'] = args.timeend
        if not args.timeend and args.timestart:
            time_range['range'][args.timefield]['lt'] = 'now'
        # only add it to query if --timestart/--timeend flags were specified
        query['query']['bool']['filter'].append(time_range)

    # build and add sort if it's not a --count query
    if not args.count:
        sort_fields = args.sort.split(',')
        if args.reverse:
            sorts = list(map(lambda field: { field: "desc"} , sort_fields))
        else:
            sorts = list(map(lambda field: { field: "asc"} , sort_fields))
        query['sort'] = sorts

    return query

def dslQuery(es, args):
    """ run a query using Elasticsearch DSL

    If passed a file, execute it as a regular DSL query.
    Otherwise, run args.query as a kibana style query_string query """
    if os.path.isfile(args.query):
        from_file = True
        with open(args.query) as file:
            query = json.loads(file.read())
    else:
        from_file = False
        query = build_query_string_query(args)

    if args.count:
        result = es.count(body=query, index=args.index, request_timeout=float(args.timeout))
        print(result['count'])
    elif args.async:
        scanner_loop = asyncio.get_event_loop()
        scanner_loop.run_until_complete(async_print_docs(es, query, args))
    else:
        print_docs(es, query, args)

def dslAggQuery(es, args):
    """ run a query and return only the query's aggregations """
    if os.path.isfile(args.query):
        with open(args.query) as file:
            query = json.loads(file.read())
    else:
        query = args.query
    return es.search(index=args.index,
                     body=query,
                     request_timeout=float(args.timeout),
                     filter_path=['aggregations'])

def sqlQuery(es, args):
    """ run an SQL query and scroll/print the results """
    if os.path.isfile(args.query):
        with open(args.query) as file:
            query = json.loads(file.read())
    else:
        query = {
            'query': args.query
        }
    sql = elasticsearch.client.sql.SqlClient(es)
    results = sql.query(body=query, params={'format': args.format}, request_timeout=float(args.timeout))
    if args.format == 'txt':
        print(results)
    elif args.format == 'json':
        print(json.dumps(results))

if __name__ == '__main__':
    signal(SIGINT, SIG_DFL)
    signal(SIGPIPE, SIG_DFL)
    global_config = load_config('/etc/esgrep/esgrep.yml')
    if os.path.exists('./esgrep.yml'):
        local_config = load_config('./esgrep.yml')
    else:
        local_config = {}
    config = {**global_config, **local_config} 

    parser = argparse.ArgumentParser(prog='esgrep', formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument('query',
                        default='*',
                        help=('query string query to pass to Elasticsearch,\n' +
                              'OR a file containing an Elasticsearch query\n' +
                              '(uses the full Elasticsearch query DSL)')
                        )
    parser.add_argument('-i', '--index',
                        default='syslog',
                        help=('index to search against. Supports wildcards\n' +
                              'For example: {0}-2016.11.01, {0}-2016.10.*, etc\n' +
                              '(defaults to "syslog")')
                        )

    # Some options won't work with async
    group = parser.add_mutually_exclusive_group()
    group.add_argument('-A', '--async',
                        action='store_true',
                        help='Use asyncio for returning query results.\n' +
                             'Will not work with --agg, --count, or --sql queries.\n' +
                             'Implies --no-preserve-order.'
                        )
    group.add_argument('-a', '--agg',
                        action='store_true',
                        help='Return only aggregations from query.'
                        )
    group.add_argument('-c', '--count',
                        action='store_true',
                        help='Return only number of matches from (non-sql) query results.'
                        )
    group.add_argument('-S', '--sql',
                        action='store_true',
                        help='Use SQL query syntax.'
                        )

    parser.add_argument('-ts', '--timestart',
                        default=False,
                        help='Starting timestamp to filter query results by.\n' +
                             'Accpets expressions like "2001-12-25T11:00:00", "now-24h", etc. See:\n' +
                             'https://www.elastic.co/guide/en/elasticsearch/reference/current/common-options.html#date-math\n' +
                             'and strict_date_optional_time||epoch_millis in:\n' +
                             'https://www.elastic.co/guide/en/elasticsearch/reference/7.17/mapping-date-format.html#built-in-date-formats'
                        )
    parser.add_argument('-te', '--timeend',
                        default=False,
                        help='Ending timestamp to filter query results by.\n' +
                             'Accepts expressions like "2001-12-25T11:00:00", "now-24h", etc. See:\n' +
                             'https://www.elastic.co/guide/en/elasticsearch/reference/current/common-options.html#date-math\n' +
                             'and strict_date_optional_time||epoch_millis in:\n' +
                             'https://www.elastic.co/guide/en/elasticsearch/reference/7.17/mapping-date-format.html#built-in-date-formats'
                        )
    parser.add_argument('-n', '--no-preserve-order',
                        action='store_false',
                        help='Do not preserve order of query results (significantly faster throughput).\n' +
                             'If exporting large amounts of data, use something like jq for sorting:\n' +
                             "cat query_results.json | jq -s 'sort_by(.[\"@timestamp\"])[]'"
                        )
    parser.add_argument('-s', '--sort',
                        default='@timestamp',
                        help='Comma separated list of fields to sort by\n' +
                             'Order is ascending by default (see -r, --reverse).\n'
                             '(defaults to "@timestamp")'
                        )
    parser.add_argument('-r', '--reverse',
                        action='store_true',
                        help='Sort by descending value instead of ascending'
                        )
    parser.add_argument('-t', '--timeout',
                        default=120.0,
                        help='How long to wait for a response from Elasticsearch\n' +
                             '(defaults to 120 seconds)'
                        )
    parser.add_argument('-f', '--format',
                        default='json',
                        help='Format to return data in (json, txt).\n' +
                             'The txt format will only work with documents containing a "message" field.'
                        )
    parser.add_argument('-F', '--full-docs',
                        action='store_true',
                        help='Return full document of results instead of only the _source field.\n' +
                             'This includes fields: like _index, _id, _score, etc'
                        )
    parser.add_argument('--timefield',
                        default='@timestamp',
                        help='Field used when applying a time range to a search\n' +
                             '(defaults to "@timestamp")'
                        )
    args = parser.parse_args()

    if args.async:
        es = elasticsearch.AsyncElasticsearch(
            hosts=config['es_nodes'],
            http_auth=(config['username'], config['password']),
            timeout=float(args.timeout)
        )
    else:
        es = elasticsearch.Elasticsearch(
            hosts=config['es_nodes'],
            http_auth=(config['username'], config['password']),
            timeout=float(args.timeout)
        )


    if args.sql:
        sqlQuery(es, args)
    elif args.agg:
        result = dslAggQuery(es, args)
        agg_json = json.dumps(result['aggregations'])
        print(agg_json)
    else:
        dslQuery(es, args)
