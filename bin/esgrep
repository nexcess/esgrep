#!/usr/bin/env python

import time
import argparse
import sys
import os
import errno
import yaml
import json
import elasticsearch
import elasticsearch.helpers

try:
    config = yaml.load(file('/etc/esgrep/esgrep.yml', 'r'))
except yaml.YAMLError as err:
    print('Error in config file:', err)

if 'default_log' not in config:
    config['default_log'] = "logstash"

parser = argparse.ArgumentParser(prog='esgrep')
parser.add_argument('-i', '--index',
                    default='{0}-{1}'.format(
                        config['default_log'],
                        time.strftime('%Y.%m.%d')),
                    help=("index to search against. Supports wildcards" +
                          " (e.g., {0}-2016.11.01, {0}-2016.10.*," +
                          "etc). defaults to {0}-YYYY-MM-DD").format(
                            config['default_log']
                          )

                    )
parser.add_argument('query',
                    default='*',
                    help=("query to search elasticsearch for. See" +
                          " elasticsearch/kibana query string syntax" +
                          "for more info")
                    )
parser.add_argument('-j', '--json',
                    action='store_true',
                    help='return all (_source) fields as json'
                    )
parser.add_argument('-ts', '--timestart',
                    default=False,
                    help='starting timestamp to filter query results by'
                    )
parser.add_argument('-te', '--timeend',
                    default="now",
                    help='ending timestamp to filter query results by'
                    )
parser.add_argument('--timefield',
                    default="@timestamp",
                    help='field used when applying a time range to a search ' +
                         '(defaults to "@timestamp")'
                    )
parser.add_argument('-s', '--sort',
                    default="@timestamp",
                    help='comma separated list of fields to sort by ' +
                         '(defaults to "@timestamp")'
                    )
parser.add_argument('-f', '--fields',
                    default="*,_source",
                    help='comma separated list of fields to search ' +
                         '(defaults to "*,_source")'
                    )

args = parser.parse_args()

time_range = {
    args.timefield: {
        "lte": args.timeend
    }
}
if args.timestart:
    time_range[args.timefield]['gte'] = args.timestart

query_string_query = {
    "query": {
        "bool": {
            "must": [
                {
                    "range": time_range,
                },
                {
                    "query_string": {
                        "query": args.query,
                        "analyze_wildcard": "true"
                    }
                }
            ]
        }
    },
    "sort": args.sort.split(','),
    "fields": args.fields.split(','),
}

if os.path.isfile(args.query):
    with open(args.query) as file:
        query = json.loads(file.read())
else:
    query = query_string_query

es = elasticsearch.Elasticsearch(hosts=config['es_nodes'])
scroller = elasticsearch.helpers.scan(
                es,
                query,
                index=args.index,
                preserve_order=True
            )

try:
    for doc in scroller:
        if args.json:
            msg = json.dumps(doc["_source"])
        else:
            msg = '{0} {1} {2} {3}'.format(
                    doc["_source"]["@timestamp"],
                    doc["_source"]["host"],
                    doc["_source"]["program"],
                    doc["_source"]["message"]
                   )
        print msg
except IOError as err:
    if err.errno == errno.EPIPE:
        sys.exit(0)
